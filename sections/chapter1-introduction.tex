\chapter{Introduction}

Reactive programming is becoming increasingly popular. Over the past decade, we have observed a slow but steady shift away from traditional imperative methodologies towards other, more declarative paradigms.
The technology landscape is moving, and with it the software development world. Web and mobile applications, the \textit{internet of things} and now virtual reality software are dominating the conversation, and they all have one thing in common: they are driven by events. Events, callbacks and asynchronous computation have always been challenging, so it's not hard to see why reactive programming - which puts events at the forefront as first class citizens - is gaining such popularity. Its declarative style and modeling of \textit{values over time} is a perfect fit for environments with many impulses, such as the web.

Evaluation models for this style of programming are plenty, but none of them come with free parallelism. As can be expected, research has already gone into parallelizing reactive programs \citep{peterson_parallel_2000}, but none have tried mapping these applications onto something that was designed to run parallel from the beginning: the dataflow model. 
This model enforces instruction execution whenever the inputs are available, contrary to the sequential model where instructions are executed one after another, which sets up the perfect conditions to run in parallel.

\section{Context}

Reactive programming nor the dataflow model are new technologies, both go back to at least the 1980s \citep{harel_development_1985, veen_dataflow_1986}. While they try to solve different problems, they do share an interesting common trait: the evaluation models of both use directed graphs to orchestrate data flowing through its applications. 

The core principle of reactive programming is making events a first class citizen: they can be listened to, transformed or even composed with other events, ultimately building a graph of nodes that represent these events and the data dependencies between them. When the application executes, data courses through this graph via the \textit{reactions} of the nodes when an event is fired. One could say that the system \textit{reacts} to every event.

The dataflow model on the other hand has a different purpose: parallelizing instructions as much as possible by isolating each instruction and executing it whenever the inputs are ready. The runtime in this scenario is responsible for tracking the inputs of each instruction and forwarding the results to other instructions that depend on it. These dependencies between instructions again form a graph. This time however, nodes in the graph represent instructions, not events. Dependencies in this graph simply indicate that one instruction takes as input the output of another. 

So while reactive programming uses a graph of nodes which represent events, the dataflow model has a graph which represents instructions. When executed, data flows through these graphs and the output of a node is forwarded to nodes further down the graph. Conceptually, nodes in these graphs mean different things in the two models, but the way that they behave is undeniably similar.

\section{Goals}

The goal of this thesis is to explore the possible benefits of running a reactive language on top of a dataflow engine, more specifically the advantages with regards to parallel execution. We propose that the update mechanism necessary to support a reactive language can be completely implemented using a dataflow engine, with the aim to parallelize the updating of separate nodes in the reactive graph. 
This would allow us to scale a reactive program horizontally, exploiting the maximum amount of parallelism possible. Moore's law essentially states that the processing power of a single processor core doubles nearly every 2 years. The last few years however, this exponential factor has been decreasing and more focus has been going towards splitting up processors into multiple cores. To make full use of these cores though, programs have to natively support parallel execution. The purpose of this thesis is therefore to investigate the parallelization of reactive programs by using the dataflow model as a platform. Given a successful mapping from reactive programming to the dataflow model, we can prove that reactive programming is a future proof paradigm, well suited for parallel evaluation. 

\section{Contributions}

In order to test our hypothesis, we present a new reactive programming language \textit{FrDataFlow}, based on Racket with a few extra features to natively support reactive programming. Expressions in this language are evaluated by our own interpreter, which builds the aforementioned graph in the background and keeps it up to date. Rather than implementing our own update mechanism however, the reactive graph is translated to instructions for our custom dataflow engine. This is the core mechanism which will orchestrate the events and keep nodes in the graph up to date.

Furthermore, we evaluate this approach by comparing it to an implementation of the same language that does not run on a dataflow engine, but applies a more traditional evaluation model. Benchmarks are provided for both latency and throughput for both implementations. Lastly, we also investigate the scaling possibilities of FrDataFlow by actually running it across multiple cores simultaneously. 
